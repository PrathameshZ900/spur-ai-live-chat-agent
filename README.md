# ğŸš€ Spur AI Live Chat Agent

A full-stack AI-powered live chat support system built with **Node.js, TypeScript, Express, MongoDB (Prisma), React, and Groq LLM API**.

This project simulates a modern AI customer support assistant capable of maintaining conversation context, persisting chat history, and generating intelligent responses in real-time.

---

## âœ¨ Features

- ğŸ’¬ Real-time AI chat interface
- ğŸ§  Context-aware responses (conversation memory)
- ğŸ—„ Persistent chat storage using MongoDB
- âš¡ Fast LLM integration using Groq
- ğŸ¨ Modern full-screen responsive UI
- ğŸ” Session-based conversation tracking
- ğŸ›¡ Robust error handling
- ğŸ§± Clean architecture (Routes â†’ Controllers â†’ Services â†’ Data Layer)

---

## ğŸ— Tech Stack

### Backend
- Node.js
- TypeScript
- Express
- MongoDB
- Prisma ORM
- Groq LLM API
- dotenv

### Frontend
- React (Vite)
- Modern responsive CSS
- Session storage for chat continuity

---

## ğŸ§  Architecture Overview

The backend follows clean separation of concerns:


Routes â†’ Controllers â†’ Services â†’ Prisma (DB)
â†“
LLM Service


- **Routes** handle HTTP endpoints
- **Controllers** validate input & orchestrate logic
- **Services** contain business logic
- **Prisma** manages database operations
- **LLM Service** encapsulates AI provider logic

This structure allows:
- Easy LLM provider switching
- Better scalability
- Clear maintainability
- Channel extensibility (WhatsApp, Instagram, etc.)

---

## ğŸ—„ Database Schema

### Conversation
- id
- createdAt
- updatedAt

### Message
- id
- conversationId
- sender ("user" | "ai")
- text
- createdAt

All conversations are persisted and associated with a sessionId.

---

## ğŸ¤– LLM Integration

Provider: **Groq**
Model: `llama-3.1-8b-instant`

The system:
- Injects a structured system prompt
- Passes recent conversation history
- Handles API failures gracefully
- Limits max tokens for cost control

---

## ğŸ§  Memory System

The chatbot maintains:
- Session-based memory (conversation history)
- Contextual continuity across messages
- Database persistence for reload support

Future improvements could include:
- Conversation summarization
- Vector-based semantic memory (RAG)
- Long-term user preference storage

---

## ğŸ¨ UI Highlights

- Full-screen immersive layout
- Modern glassmorphism styling
- Typing animation
- Auto-scroll to latest message
- Responsive design (desktop & mobile)
- Clean chat bubble differentiation

---

# âš™ï¸ Setup Instructions

---

## 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/your-username/spur-ai-live-chat-agent.git
cd spur-ai-live-chat-agent

2ï¸âƒ£ Backend Setup

cd backend
npm install

Create .env
PORT=5000
DATABASE_URL="your_mongodb_connection_string"
GROQ_API_KEY="your_groq_api_key"
GROQ_MODEL="llama-3.1-8b-instant"
Generate Prisma Client
npx prisma generate
npx prisma db push
Start Backend
npm run dev

Server runs on:

http://localhost:5000
3ï¸âƒ£ Frontend Setup
cd ../frontend
npm install
npm run dev

Frontend runs on:

http://localhost:5173
ğŸ§ª Test Scenarios

Try:

"Hello"

"What is your return policy?"

"Do you ship to USA?"

Long message

Refresh page (chat persists)

ğŸ›¡ Error Handling

Input validation (empty message rejection)

API failure fallback message

Graceful rate-limit handling

No server crashes on invalid input

ğŸ“ˆ Scalability Considerations

If scaling to production:

Horizontal backend scaling behind load balancer

Redis for session caching

Rate limiting middleware

Vector database for retrieval-based responses

Monitoring & logging (Sentry, Winston)

Token usage tracking

ğŸ”® Future Improvements

Streaming responses (real-time token rendering)

Markdown rendering support

Authentication system

Multi-channel integration (WhatsApp, Instagram)

Admin dashboard

Analytics & conversation insights

Smart memory summarization

ğŸ’¡ Why This Project Matters

This project demonstrates:

Clean backend architecture

AI system integration

Conversation persistence

Cost-aware LLM usage

Product-level UX thinking

Extensible system design

It closely resembles what a founding engineer would build for a modern AI customer engagement platform.

ğŸ‘¨â€ğŸ’» Author

Prathamesh Magar

Full-stack developer focused on AI systems, backend architecture, and scalable product design.

â­ If You Like This Project

Give it a star â­
Feel free to fork and improve it.



---


# ğŸ¯ Why This README Is Strong


This README:


- Shows technical depth  
- Shows product thinking  
- Shows architecture clarity  
- Shows scalability awareness  
- Sounds professional  
- Impresses interviewers  


---


If you want, I can now give you:


- ğŸ§  â€œRecruiter-friendlyâ€ shorter version
- ğŸ† Enterprise-level README
- ğŸ“¦ Deployment section for Render/Vercel
- ğŸ”¥ Badge-enhanced premium GitHub version
- ğŸ’¬ How to pitch this in 60 seconds confidently


Tell me what level you want ğŸš€
